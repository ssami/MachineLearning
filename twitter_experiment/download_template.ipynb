{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests, base64, json, urllib, time, re\n",
    "import pandas as pd\n",
    "\n",
    "cleaned_data = 'xxxx'\n",
    "tdata = pd.DataFrame.from_csv(cleaned_data, sep='\\t')\n",
    "sample_count = tdata['tweet_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now to get the bearer token\n",
    "uenc_con_key = consumer_key # right now encoding doesn't change format\n",
    "uenc_con_secret = consumer_secret # right now encoding doesn't change format\n",
    "concat_string = uenc_con_key + ':' + uenc_con_secret\n",
    "b64_concat_string = base64.b64encode(concat_string)\n",
    "body = \"grant_type=client_credentials\"\n",
    "headers = {}\n",
    "headers['Authorization'] = 'Basic ' + b64_concat_string\n",
    "headers['Content-Type'] = 'application/x-www-form-urlencoded;charset=UTF-8'\n",
    "r = requests.post(oauth_url, data=body, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now prep for the actual batch call \n",
    "access_token = r.json()['access_token']\n",
    "b64_bearer = base64.b64encode(access_token)\n",
    "headers = {}\n",
    "headers['Authorization'] = 'Bearer ' + access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now that we have the headers, we set up some basic variables\n",
    "tweet_csv_prefix = 'tweets_lang_'\n",
    "csv_suffix = '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_url = 'https://api.twitter.com/1.1/statuses/lookup.json?id='\n",
    "tweet_number = 99\n",
    "idx = 0\n",
    "delim = ','\n",
    "sleep_time = 10 # in seconds\n",
    "\n",
    "while idx < sample_count: \n",
    "    \n",
    "    # batch call to get 99 tweets\n",
    "    tweet_full = tweet_url + str(tweet_number) + delim\n",
    "    idx_end = idx + tweet_number\n",
    "    ids = \"\"\n",
    "    \n",
    "    # concat tweet ids \n",
    "    for i in tdata.iloc[idx:idx_end]['tweet_id']: \n",
    "        ids += str(i) + delim\n",
    "        \n",
    "    tweet_full = tweet_full + ids[:-1] # remove last comma \n",
    "    tweet_full = tweet_full[:-1]\n",
    "    \n",
    "    # make requests for 99 tweets at a time\n",
    "    r = requests.get(tweet_full, headers=headers)\n",
    "    \n",
    "    # if the status is not successful, \n",
    "    # continue without changing idx\n",
    "    # so we can re-try the index \n",
    "    if (r.status_code != 200):\n",
    "        print \"error: \" + r.text\n",
    "        time.sleep(60)\n",
    "        continue\n",
    "    tweet = r.text\n",
    "    jtweet = json.loads(tweet)\n",
    "    lang_list = []\n",
    "    text_list = []\n",
    "    # store found tweets and corresponding langs\n",
    "    for t in jtweet: \n",
    "        if t['text'] is not None and len(t['text']) > 0: \n",
    "            text = t['text']\n",
    "            text = re.sub('\\n', '', text)\n",
    "            lang_loc = tdata[tdata['tweet_id'] == t['id']]\n",
    "            if not lang_loc.empty:\n",
    "                lang = lang_loc['language'].values[0]\n",
    "                lang_list.append(lang)\n",
    "                text_list.append(text)\n",
    "        else: \n",
    "            print t['id'] + \" not found!\"\n",
    "    \n",
    "    # write to data structure\n",
    "    smp = []\n",
    "    smp = zip(text_list, lang_list)\n",
    "    \n",
    "    # store in temporary csv file \n",
    "    idx += tweet_number\n",
    "    print \"End idx: \", idx # csv file tracks last index we stopped at \n",
    "    csv_name = tweet_csv_prefix + str(idx) + csv_suffix\n",
    "    df = pd.DataFrame(data=smp, columns=['tweet', 'lang'])\n",
    "    df.to_csv(csv_name, index=False, header=False, sep='\\t', encoding='utf-8')\n",
    "    time.sleep(sleep_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
